{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Complete-Workflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Mathis1993/Leaf-Classification-CNN/blob/master/Complete_Workflow.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "1HPCy6Gm4EWA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Plant Species Classification using a CNN"
      ]
    },
    {
      "metadata": {
        "id": "oVbjJGpHmi0K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"http://drive.google.com/uc?export=view&id=1JyQxgUQk_K4v3LGdeFJlBMABN-WKJt6b\">"
      ]
    },
    {
      "metadata": {
        "id": "ITK-kWQGR0bg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ]
    },
    {
      "metadata": {
        "id": "jI9NdgAC4EWF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In the course of learning about AI at [TechLabs](https://tech-labs.de/), we realized a small project to classify plant species using a Convolutional Neural Network (CNN).\n",
        "\n",
        "In 2012, Neeraj Kumar et al. developed [Leafsnap: A Computer Vision System for Automatic Plant Species Identification](https://neerajkumar.org/base/papers/nk_eccv2012_leafsnap.pdf), a mobile app that identifies all 185 tree species in the Northeastern United States using pictures of their leaves. The classification process is based on a computer vision sytem. This system segments the leaf from its background, extracts curvature features of the leaf's contour and classifies it against a dataset containing examples of all the 185 tree species. With this procedure, a top-1 score of about 72% is achieved (meaning that in 72% of cases, the tree species class the computer vision systems assigns the highest probability to is the correct one). \n",
        "\n",
        "Examples of 180 of the 185 different plant species can be examined in the image above.\n",
        "\n",
        "Using this same dataset, that the authors of the paper make available [here](leafsnap.com/dataset/), we asked ourselves if we could possibly beat the traditional computer vision system's performance by implementing the classification task via a CNN. To maximize our learning success, we did not use a pretrained CNN, but built our own network architecture.\n",
        "\n",
        "In this post, we want to give a full overview of all the steps we took to train our CNN to classify Northeastern American tree species.\n",
        "\n",
        "Due to limited computational resources on our private hardware, we used [Google Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb), Google's free cloud service for developing deep Iearning applications on a GPU. We will show the necessary steps for getting ready to work, a detailed tutorial is available on [medium](https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d)."
      ]
    },
    {
      "metadata": {
        "id": "R99hBGehRuu4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Google Colaboratory"
      ]
    },
    {
      "metadata": {
        "id": "M5ZXvoKTTnON",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In order to use Google Colaboratory, we worked in a IPython Notebook located in a Google Drive storage. \n",
        "\n",
        "**Important**: To use the free GPU, go to \"Edit-->Notebook Settings\" and select \"GPU\" as hardware accelerator. \n",
        "\n",
        "Once connected, Drive can be mounted to Google Colab so that files stored in Drive will be available using the code snippet below."
      ]
    },
    {
      "metadata": {
        "id": "EzvucxyW4xWb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "ce02436f-ff11-4fdf-b9c4-42da9782aff6"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mIOcKZ7BT6iv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then, we can navigate to the desired directory..."
      ]
    },
    {
      "metadata": {
        "id": "pBJUSjVT4ysL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4fae993e-4e85-49cf-c3ea-c47b9929d8a4"
      },
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/CNN-Model-files"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/CNN-Model-files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6E-GugQiS6PE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "... and start working."
      ]
    },
    {
      "metadata": {
        "id": "dt8soZ4z4EWI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "fboX9qegCPkd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Consisting of the following steps:\n",
        "1. Import packages\n",
        "2. Read data frame with information about pictures\n",
        "3. Create numeric labels\n",
        "4. Resize Pictures \n",
        "6. Read pictures as RGB arrays\n",
        "7. Randomize picture order\n",
        "8. Stack picture input into one array\n",
        "9. Normalize input features (pictures) and one-hot encode labels"
      ]
    },
    {
      "metadata": {
        "id": "nyzibeCIUyCH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Import packages"
      ]
    },
    {
      "metadata": {
        "id": "37OIHSaA4EWM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As a first step, we import the packages necessary for preprocessing the data. "
      ]
    },
    {
      "metadata": {
        "id": "sC23UEBw4EWO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import PIL\n",
        "#from PIL import ImageOps\n",
        "import imageio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O1UbVqVHU5Wo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Read data frame with information about pictures"
      ]
    },
    {
      "metadata": {
        "id": "9zp6wtyj_kYC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In the dataset, there is a data frame containing information about the pictures. Relevant for us are the columns:\n",
        "- path: path to the individual pictures\n",
        "- species: latin term for each plant\n",
        "- source: picture taken in lab or field"
      ]
    },
    {
      "metadata": {
        "id": "uOUlCZxg4EWt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8e53d9f9-fb71-4fb3-92c4-a7ac766001cf"
      },
      "cell_type": "code",
      "source": [
        "img_info = pd.read_csv(\"./leafsnap-dataset-images.txt\", sep=\"\\t\")\n",
        "#img_info = pd.read_csv(\"./Dataset/leafsnap-dataset-images.txt\", sep=\"\\t\")\n",
        "img_info.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>image_path</th>\n",
              "      <th>segmented_path</th>\n",
              "      <th>species</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>55497</td>\n",
              "      <td>dataset/images/lab/abies_concolor/ny1157-01-1.jpg</td>\n",
              "      <td>dataset/segmented/lab/abies_concolor/ny1157-01...</td>\n",
              "      <td>Abies concolor</td>\n",
              "      <td>lab</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55498</td>\n",
              "      <td>dataset/images/lab/abies_concolor/ny1157-01-2.jpg</td>\n",
              "      <td>dataset/segmented/lab/abies_concolor/ny1157-01...</td>\n",
              "      <td>Abies concolor</td>\n",
              "      <td>lab</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>55499</td>\n",
              "      <td>dataset/images/lab/abies_concolor/ny1157-01-3.jpg</td>\n",
              "      <td>dataset/segmented/lab/abies_concolor/ny1157-01...</td>\n",
              "      <td>Abies concolor</td>\n",
              "      <td>lab</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>55500</td>\n",
              "      <td>dataset/images/lab/abies_concolor/ny1157-01-4.jpg</td>\n",
              "      <td>dataset/segmented/lab/abies_concolor/ny1157-01...</td>\n",
              "      <td>Abies concolor</td>\n",
              "      <td>lab</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>55501</td>\n",
              "      <td>dataset/images/lab/abies_concolor/ny1157-02-1.jpg</td>\n",
              "      <td>dataset/segmented/lab/abies_concolor/ny1157-02...</td>\n",
              "      <td>Abies concolor</td>\n",
              "      <td>lab</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   file_id                                         image_path  \\\n",
              "0    55497  dataset/images/lab/abies_concolor/ny1157-01-1.jpg   \n",
              "1    55498  dataset/images/lab/abies_concolor/ny1157-01-2.jpg   \n",
              "2    55499  dataset/images/lab/abies_concolor/ny1157-01-3.jpg   \n",
              "3    55500  dataset/images/lab/abies_concolor/ny1157-01-4.jpg   \n",
              "4    55501  dataset/images/lab/abies_concolor/ny1157-02-1.jpg   \n",
              "\n",
              "                                      segmented_path         species source  \n",
              "0  dataset/segmented/lab/abies_concolor/ny1157-01...  Abies concolor    lab  \n",
              "1  dataset/segmented/lab/abies_concolor/ny1157-01...  Abies concolor    lab  \n",
              "2  dataset/segmented/lab/abies_concolor/ny1157-01...  Abies concolor    lab  \n",
              "3  dataset/segmented/lab/abies_concolor/ny1157-01...  Abies concolor    lab  \n",
              "4  dataset/segmented/lab/abies_concolor/ny1157-02...  Abies concolor    lab  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "iuuUfnYwAz_v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We create a new column only holding the filenames and not the whole path to each picture, so that we can assess the filenames for later resizing of the pictures."
      ]
    },
    {
      "metadata": {
        "id": "Eh37RuFvBBkk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_info[\"filename\"] = None\n",
        "index_filename = img_info.columns.get_loc(\"filename\")\n",
        "for i in range(len(img_info)):\n",
        "    img_info.iloc[i, index_filename] = os.path.basename(str(img_info[\"image_path\"][i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m6gxVXnMVOFt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. Create numeric labels"
      ]
    },
    {
      "metadata": {
        "id": "ErbFWP2zBE67",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then, we want to have numeric labels instead of the latin term for each plant, so we append another column holding these.\n",
        "- In the data frame, all images of one species are listed consecutively (first the lab images, then the field images)\n",
        "- Therefore we just loop over the dataframe and increment the numeric label whenever we encounter a latin term that differs from the previous one"
      ]
    },
    {
      "metadata": {
        "id": "R7jN-mpeBRDB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "23cceb3f-3b46-47fa-c6d2-ab2009bc4342"
      },
      "cell_type": "code",
      "source": [
        "#new column (empty)\n",
        "img_info[\"labels_integer\"] = None\n",
        "#index of new column\n",
        "index_labels_integer = img_info.columns.get_loc(\"labels_integer\")\n",
        "#index of species column\n",
        "index_species = img_info.columns.get_loc(\"species\")\n",
        "#to assign numeric labels starting with 0 for the first species\n",
        "k = 0 \n",
        "for i in range(len(img_info)):\n",
        "    if i == 0:\n",
        "        img_info.iloc[i, index_labels_integer] = k #here, k == 0\n",
        "    if i > 0:\n",
        "        if img_info.iloc[i-1, index_species] == img_info.iloc[i, index_species]:\n",
        "            img_info.iloc[i, index_labels_integer] = k\n",
        "        else:\n",
        "            k += 1\n",
        "            img_info.iloc[i, index_labels_integer] = k\n",
        "img_info.tail()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>image_path</th>\n",
              "      <th>segmented_path</th>\n",
              "      <th>species</th>\n",
              "      <th>source</th>\n",
              "      <th>filename</th>\n",
              "      <th>labels_integer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>55497</td>\n",
              "      <td>dataset/images/lab/abies_concolor/ny1157-01-1.jpg</td>\n",
              "      <td>dataset/segmented/lab/abies_concolor/ny1157-01...</td>\n",
              "      <td>Abies concolor</td>\n",
              "      <td>lab</td>\n",
              "      <td>ny1157-01-1.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55498</td>\n",
              "      <td>dataset/images/lab/abies_concolor/ny1157-01-2.jpg</td>\n",
              "      <td>dataset/segmented/lab/abies_concolor/ny1157-01...</td>\n",
              "      <td>Abies concolor</td>\n",
              "      <td>lab</td>\n",
              "      <td>ny1157-01-2.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>55499</td>\n",
              "      <td>dataset/images/lab/abies_concolor/ny1157-01-3.jpg</td>\n",
              "      <td>dataset/segmented/lab/abies_concolor/ny1157-01...</td>\n",
              "      <td>Abies concolor</td>\n",
              "      <td>lab</td>\n",
              "      <td>ny1157-01-3.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>55500</td>\n",
              "      <td>dataset/images/lab/abies_concolor/ny1157-01-4.jpg</td>\n",
              "      <td>dataset/segmented/lab/abies_concolor/ny1157-01...</td>\n",
              "      <td>Abies concolor</td>\n",
              "      <td>lab</td>\n",
              "      <td>ny1157-01-4.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>55501</td>\n",
              "      <td>dataset/images/lab/abies_concolor/ny1157-02-1.jpg</td>\n",
              "      <td>dataset/segmented/lab/abies_concolor/ny1157-02...</td>\n",
              "      <td>Abies concolor</td>\n",
              "      <td>lab</td>\n",
              "      <td>ny1157-02-1.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   file_id                                         image_path  \\\n",
              "0    55497  dataset/images/lab/abies_concolor/ny1157-01-1.jpg   \n",
              "1    55498  dataset/images/lab/abies_concolor/ny1157-01-2.jpg   \n",
              "2    55499  dataset/images/lab/abies_concolor/ny1157-01-3.jpg   \n",
              "3    55500  dataset/images/lab/abies_concolor/ny1157-01-4.jpg   \n",
              "4    55501  dataset/images/lab/abies_concolor/ny1157-02-1.jpg   \n",
              "\n",
              "                                      segmented_path         species source  \\\n",
              "0  dataset/segmented/lab/abies_concolor/ny1157-01...  Abies concolor    lab   \n",
              "1  dataset/segmented/lab/abies_concolor/ny1157-01...  Abies concolor    lab   \n",
              "2  dataset/segmented/lab/abies_concolor/ny1157-01...  Abies concolor    lab   \n",
              "3  dataset/segmented/lab/abies_concolor/ny1157-01...  Abies concolor    lab   \n",
              "4  dataset/segmented/lab/abies_concolor/ny1157-02...  Abies concolor    lab   \n",
              "\n",
              "          filename  labels_integer  \n",
              "0  ny1157-01-1.jpg               0  \n",
              "1  ny1157-01-2.jpg               0  \n",
              "2  ny1157-01-3.jpg               0  \n",
              "3  ny1157-01-4.jpg               0  \n",
              "4  ny1157-02-1.jpg               0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "YnIVwX0bV9BT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. Resize pictures"
      ]
    },
    {
      "metadata": {
        "id": "ixg0Nz1UAnl_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next on the list: Resizing the pictures. This is done by reading the filenames from the data frame, generating a cropped version of the desired size for each picture and saving them to an output directory."
      ]
    },
    {
      "metadata": {
        "id": "vpftFPk84EWn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def resizeImage(infile, infile_name_only, output_dir=\"\", size=(1024,768)):\n",
        "  '''\n",
        "  Resize Images to a requestet size (not considerinng aspect ratio)\n",
        "  Input:\n",
        "  - infile: image to be resized (with path)\n",
        "  - infile_name_only: image to be resized (filename only)\n",
        "  - output_dir: where resized images should be stored\n",
        "  - size: output size (tupel of (height, width))\n",
        "  '''\n",
        "  \n",
        "  outfile = os.path.splitext(infile_name_only)[0]\n",
        "  extension = os.path.splitext(infile)[1]\n",
        "\n",
        "  if infile != outfile:\n",
        "    try :\n",
        "      im = PIL.Image.open(infile)\n",
        "      #crops to requested size independt from aspec ratio\n",
        "      im = im.resize(size, PIL.Image.ANTIALIAS) \n",
        "      im.save(output_dir + \"/\" + outfile + extension)\n",
        "    except IOError:\n",
        "      print(\"cannot reduce image for \", infile)\n",
        "\n",
        "output_dir = \"./Dataset/resized\"\n",
        "size = (256, 256)\n",
        "filenames_dir = list(img_info[\"image_path\"])\n",
        "filenames = list(img_info[\"filename\"])\n",
        "            \n",
        "#for i in range(len(filenames)):\n",
        "#    resizeImage(filenames_dir[i], filenames[i], output_dir=output_dir, size=size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6cbw_p-BWCqT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5. Read pictures as RGB arrays"
      ]
    },
    {
      "metadata": {
        "id": "JWwkZnAGBq92",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "RGB arrays: All resized images are read as rgb arrays in the order they are listed in the data frame. An RGB array is a numeric representation of a picture, assigning three color values (one for each of the three channels: red, green and blue) to each pixel. From a 64x64 picture, we therefore get a 64x64x3 rgb array.\n"
      ]
    },
    {
      "metadata": {
        "id": "XCQ_MHeXHnvr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "list_vectors = []\n",
        "\n",
        "for i in range(len(img_info_red)):\n",
        "    #path to resized images\n",
        "    file = \"C:\\\\Users\\Mathis\\\\sciebo\\\\Machine Learning\\\\Projekt TechLabs\\\\Dataset\\\\resized\" + \"\\\\\" + img_info_red.iloc[i, index_filename]\n",
        "    #read as rgb array\n",
        "    img = imageio.imread(file)\n",
        "    #append image vector to list\n",
        "    list_vectors.append(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gVZa62EbWGPr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 6. Randomize picture order"
      ]
    },
    {
      "metadata": {
        "id": "w1vvG2s4JUuZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As a next step, we want to randomize the order in which the picture data is fed to the CNN to prevent sequence effects, as the data frame comes ordered by species."
      ]
    },
    {
      "metadata": {
        "id": "v6_B6nfsJsde",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#relevant variables\n",
        "label = img_info_red[\"species\"]\n",
        "source = img_info_red[\"source\"]\n",
        "label_numeric = img_info_red[\"labels_integer\"]\n",
        "list_vectors = list_vectors\n",
        "filename = img_info_red[\"filename\"]\n",
        "\n",
        "#randomization\n",
        "allinfo = list(zip(label, source, label_numeric, list_vectors, filename)) \n",
        "random.shuffle(allinfo) #shuffle\n",
        "label, source, label_numeric, list_vectors, filename = zip(*allinfo) #decompose again\n",
        "img_info_rand = pd.DataFrame({\"filename\":filename, \"label\":label, \"source\":source, \"label_numeric\":label_numeric}) #store picture information in randomized order"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TtBoxoW3WLEE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 7. Stack picture input into one array"
      ]
    },
    {
      "metadata": {
        "id": "ToAKZFMHJ4vc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, the picture vectors should be stacked vertically into one array, so that each row represents one picture. This array's shape should then be (30866, 64, 64, 3), as we have 30866 pictures, represented in a 64x64x3 array each. "
      ]
    },
    {
      "metadata": {
        "id": "YDszhhPUKGw8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = np.stack((list_vectors))\n",
        "\n",
        "#transform numeric labels into array\n",
        "Y = np.asarray(label_numeric)\n",
        "\n",
        "print(X.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UeIF1fBZWTjT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 8. Normalize input features (pictures) and one-hot encode labels"
      ]
    },
    {
      "metadata": {
        "id": "42MpuqIhKNrz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, we normalize the picture data (dividing by 255, as there are 255 conditions possible for each rgb channel) and one-hot encode the numeric labels. One-hot encoding means to go from a representation where each numeric label is just one number (eg 14 for the 14th of 185 classes, so that we have a vector with 30866 entries for our 30866 pictures), to a representation where in a array each column represents a class and each row a picture. Here, picture number n being of class 14 is represented in the nth row, and only the 14th column contains a one, while all others hold zeros."
      ]
    },
    {
      "metadata": {
        "id": "WrdRFTMpK3Zi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = X/255\n",
        "Y_one_hot = keras.utils.to_categorical(Y, num_classes=185)\n",
        "print(Y.shape, Y_one_hot.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q2nvWLKqLkbX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can save the input features, labels, and the further information about the pictures (in the randomized order) so that we don't have to repeat all the above steps in the next session."
      ]
    },
    {
      "metadata": {
        "id": "_QJgpYjNLoJY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.savez(\"x_images_arrays\", X)\n",
        "np.savez(\"y_numeric_labels\", Y_one_hot)\n",
        "img_info_rand.to_csv(\"img_info_rand_field.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2YR0x_L5LEUw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN-Model"
      ]
    },
    {
      "metadata": {
        "id": "rXlBqstePxvk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In order to train a CNN on our dataset, we take the following steps:\n",
        "1. Import packages\n",
        "2. Split data in train-/development-/test-set\n",
        "3. Define the model architecture and compile the model\n",
        "4. Fit the data"
      ]
    },
    {
      "metadata": {
        "id": "EMNj2sRyXy4C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Import packages"
      ]
    },
    {
      "metadata": {
        "id": "FA2MyN45Lwn4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, we import the necessary packages."
      ]
    },
    {
      "metadata": {
        "id": "wbvAr-XOLDv0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "11766b1b-5c67-4246-fd9c-2177373dea8e"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import SGD\n",
        "from keras import regularizers"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZAWMnW_EX1kn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Split data in train-/development-/test-set"
      ]
    },
    {
      "metadata": {
        "id": "iArEjV6XQQ_0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we split our picture arrays (and the corresponding labels) into three parts:\n",
        "1. train-set: The data we train the model on (here 80%)\n",
        "2. development-set (dev-set): The data we use to evaluate the model's generalization performance (to new, unseen data) during training (here 10%)\n",
        "3. test-set: The data we want to predict using our trained model (here 10%)\n",
        "  - For further evaluation of results, we isolate labels (latin terms), numeric labels, filenames and source (lab/field) for the test-set"
      ]
    },
    {
      "metadata": {
        "id": "Su3ts69hPwGD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "split_train = 0.8 #train 0.8, validate 0.1, test 0.1\n",
        "split_val = 0.9\n",
        "index_train = int(split_train*len(X))\n",
        "index_val = int(split_val*len(X))\n",
        "\n",
        "X_train = X[:index_train]\n",
        "X_val = X[index_train:index_val]\n",
        "X_test = X[index_val:]\n",
        "\n",
        "Y_train = Y[:index_train]\n",
        "Y_val = Y[index_train:index_val]\n",
        "Y_test = Y[index_val:]\n",
        "\n",
        "#for later predictions on test set\n",
        "labels_numeric_test = info.loc[index_val:len(X), \"label_numeric\"]\n",
        "labels_test = info.loc[index_val:len(X), \"label\"]\n",
        "filenames_test = info.loc[index_val:len(X), \"filename\"]\n",
        "source_test = info.loc[index_val:len(X), \"source\"]\n",
        "\n",
        "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t5uh_xBwRhdL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. Define the model architecture and compile the model"
      ]
    },
    {
      "metadata": {
        "id": "Sx7o-1o2YAFL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For our model, we used the following architecture:\n",
        "1. Convolutional layer with Batch-Normalization and ReLU-Actiavtion\n",
        "  - filter size (5,5), 32 filters, no padding, stride (1,1)\n",
        "  - input: (64,64,3) / output: (60,60,32)\n",
        "2. Pooling layer\n",
        "  - pooling size (2,2), "
      ]
    },
    {
      "metadata": {
        "id": "2oAGhayBRgvb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hvZRONHiX7Q0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. Fit the data"
      ]
    },
    {
      "metadata": {
        "id": "XU72bhOsX-TI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}